llm:
  providers:
    ollama:
      base_url: http://localhost:11434
      default_model: llama3
      models:
        llama3:
          context_length: 4096
          temperature: 0.7
        deepseek-r1:
          context_length: 8192
          temperature: 0.7
    openai:
      default_model: gpt-3.5-turbo 